# ðŸš€ FleetOps â€“ Production Incident Response Lab

This repository is a **working production-style lab**, not just a case study.

### What this project demonstrates
- A real running backend service (Python + Flask)
- Live metrics exposure using Prometheus
- Latency SLO monitoring and alerting
- Incident response using documented runbooks
- Post-incident analysis with written postmortems

### Architecture
- **Service:** Python Flask API
- **Monitoring:** Prometheus
- **Alerts:** Burn-rate style latency alert
- **Infra:** Docker + Docker Compose
  

## FleetOps â€” PE Incident Lab  
### Production Engineering case study: SLOs â€¢ burn-rate alerts â€¢ runbooks â€¢ capacity planning â€¢ postmortems â€¢ change safety

<p>
  <img alt="Status" src="https://img.shields.io/badge/status-active-success">
  <img alt="Focus" src="https://img.shields.io/badge/focus-Production%20Engineering-blue">
  <img alt="Docs" src="https://img.shields.io/badge/artifact-documentation--first-informational">
</p>

**What this repo shows:** how I would operate and harden a high-traffic service in production â€” with operational rigor.

</div>

**Notes:** Docs-first PE portfolio artifact: SLOs, runbooks, postmortems, change safety.


---

## Why this maps strongly to Meta Production Engineering
Meta PEs debug **live production** issues, define **SLOs**, enforce paging discipline, write runbooks to reduce MTTR, and plan capacity for peak traffic.

This repo demonstrates:
- **Reliability & performance**: SLOs, error budgets, burn-rate alerts  
- **Incident response**: triage â†’ mitigation â†’ validation â†’ postmortem  
- **Capacity planning**: headroom, scaling triggers, burst modeling  
- **Change safety**: canary, rollback, risk controls

---

## System modeled

Clients
  â†“
API Gateway (routing, rate limiting, canary controls)
  â†“
User Service â€”â€” Cache
  â†“
Feed Service â€”â€” Cache â€”â€” DB
  â†“
Observability (metrics + logs + traces)
  â†“
Alerts â†’ On-call â†’ Runbook â†’ Mitigation â†’ Postmortem â†’ Prevention


## Quick start (recruiter path)
1) `docs/02_slos_and_alerts.md`  
2) `docs/03_runbooks.md`  
3) `docs/06_postmortems/`  
4) `docs/08_change_management.md`

Tip: Start with SLOs â†’ Runbooks â†’ Postmortems to see incident handling end-to-end.

## Key artifacts
- SLOs & alerts: `docs/02_slos_and_alerts.md`
- Runbooks: `docs/03_runbooks.md`
- Postmortems: `docs/06_postmortems/`
- Change safety: `docs/08_change_management.md`


## Docs index
- `docs/00_overview.md` â€” scope + how to read
- `docs/01_architecture.md` â€” system + failure domains
- `docs/02_slos_and_alerts.md` â€” SLOs, error budgets, burn-rate alerts
- `docs/03_runbooks.md` â€” triage â†’ mitigate â†’ validate
- `docs/04_capacity_planning.md` â€” headroom, scaling triggers
- `docs/05_incident_simulations.md` â€” game days + drills
- `docs/06_postmortems/` â€” incident writeups + prevention
- `docs/07_oncall_playbook.md` â€” oncall habits + escalation
- `docs/08_change_management.md` â€” canary/rollback + guardrails
- `docs/09_risk_register.md` â€” risks + mitigations
- `docs/10_operational_metrics.md` â€” golden signals + dashboards






